# ğŸ§  Research Paper Q&A Agent

Your personal AI-powered research assistant that finds, reads, and explains research papers for you!

---

## ğŸ“Œ What is this?

The **Research Paper Q&A Agent** is a full-stack AI tool that:

ğŸ” Searches and downloads research papers based on user queries using **Arxiv API**  
ğŸ“„ Extracts and parses PDF content  
ğŸ“¦ Chunks and embeds documents using **LangChain** + **FAISS**  
ğŸ¤– Uses **Ollama-powered LLMs** for local, private RAG (Retrieval-Augmented Generation)  
ğŸ’¬ Allows users to ask any question related to the downloaded paper and get factual, citation-grounded answers  
ğŸŒ Has a beautifully designed **Streamlit frontend** with a split layout â€” download and Q&A are handled separately!

---

## ğŸš€ Features

- ğŸ” **Smart ArXiv Search**: Enter your topic and fetch the top relevant research paper (PDF + metadata).
- ğŸ“¥ **PDF Download**: Downloaded only if not already present.
- ğŸ§© **Text Splitting & Embedding**: Powered by `PyMuPDF` and `LangChain`'s `RecursiveCharacterTextSplitter`.
- ğŸ§  **Local LLM Q&A**: Uses **Ollama** models like `llama3`, `mistral`, `nomic-embed-text`.
- ğŸ§  **Multi-question Insight**: Ask predefined research-related questions (summary, contributions, methodology, etc.).
- âœï¸ **Freeform Questions**: Ask any question based on the paper, with grounded answers.
- ğŸŒˆ **Interactive UI**: Modern two-column Streamlit layout separating download and Q&A logic.

---

## ğŸ—‚ï¸ Project Structure

research_agent/
â”‚
â”œâ”€â”€ data/

â”‚ â””â”€â”€ raw_papers/ # Downloaded PDFs
â”‚
â”œâ”€â”€ embeddings/

â”‚ â””â”€â”€ faiss_index/ # FAISS index from chunk embeddings
â”‚
â”œâ”€â”€ utils/

â”‚ â”œâ”€â”€ fetch_papers.py # Arxiv paper search + metadata fetcher

â”‚ â”œâ”€â”€ parse_pdf.py # PDF loader and chunker

â”‚ â”œâ”€â”€ chunk_embed.py # FAISS embedding creation

â”‚ â””â”€â”€ rag_agent.py # LangChain RAG pipeline + Q&A logic
â”‚
â”œâ”€â”€ app.py # Streamlit frontend (UI logic)

â””â”€â”€ README.md # You're here!


---

## âš™ï¸ Tech Stack

| Layer         | Tools/Frameworks                         |
|---------------|------------------------------------------|
| ğŸ”— Backend     | Python, LangChain, FAISS, Ollama          |
| ğŸ§  LLM         | Ollama (`llama3`, `mistral`, `nomic-embed`) |
| ğŸ“„ PDF Parsing | PyMuPDF, LangChain loaders               |
| ğŸ–¥ï¸ Frontend     | Streamlit (Dark themed, 2-column layout) |
| ğŸ“¡ APIs        | ArXiv API (no key required)              |

---

## ğŸ’¡ How It Works (Workflow)

1. **User enters a query** like `"Graph Transformers with PyTorch"`  
2. App fetches the top matching paper from Arxiv  
3. If PDF already exists â†’ skip download âœ…  
4. Else download it to `data/raw_papers/`  
5. If FAISS index exists â†’ reuse it âœ…  
6. Else parse â†’ chunk â†’ embed the PDF  
7. Now ask any question â€” system answers only from that paper's content  
8. Done! ğŸ¯

---


ğŸ§ª Supported Ollama Models
llama3

mistral

nomic-embed-text

ğŸ‘‰ Make sure to pull them first:
ollama pull llama3
ollama pull mistral
ollama pull nomic-embed-text


ğŸ™Œ Acknowledgements
Thanks to:

LangChain

Ollama

Streamlit

ArXiv for open-access research


ğŸ§”â€â™‚ï¸ Author
Made with ğŸ’» by Karan Shelar

ğŸŒŸ Show Your Support
If you like this project, donâ€™t forget to:

â­ Star it on GitHub
ğŸ´ Fork it
ğŸš€ Share it with others!
